import streamlit as st
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# ==================== APIå¯†é’¥å®‰å…¨æ£€æŸ¥ ====================
if 'OPENAI_API_KEY' in st.secrets:
    api_key = st.secrets['OPENAI_API_KEY']
    st.success("âœ… APIå¯†é’¥åŠ è½½æˆåŠŸ")
else:
    st.error("âŒ è¯·åœ¨Streamlit Cloudçš„Secretsä¸­é…ç½®APIå¯†é’¥")
    st.stop()  # æ²¡æœ‰å¯†é’¥å°±åœæ­¢æ‰§è¡Œ
# =======================================================

# è®¾ç½®ç½‘é¡µæ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(page_title="è‹±æ–‡è¡¨è¾¾å‚è€ƒåŠ©æ‰‹", page_icon="ğŸŒ")
st.title("ğŸŒ è‹±æ–‡è¡¨è¾¾å‚è€ƒåŠ©æ‰‹")
st.markdown("è¾“å…¥ä¸­æ–‡ï¼Œè·å–å¤šç§æƒ…æ™¯çš„è‹±æ–‡è¡¨è¾¾å‚è€ƒ")

# åœ¨ä¾§è¾¹æ ä¸­æ·»åŠ é£æ ¼é€‰æ‹©
with st.sidebar:
    st.header("ğŸ›ï¸ è®¾ç½®")
    
    # ä½¿ç”¨session_stateä¿å­˜é€‰æ‹©
    if "style_preference" not in st.session_state:
        st.session_state.style_preference = "ç»¼åˆæ¨è"
    
    style_preference = st.selectbox(
        "åå¥½é£æ ¼",
        options=["ç»¼åˆæ¨è", "å£è¯­äº¤æµ", "å•†åŠ¡ä¹¦é¢", "å­¦æœ¯å†™ä½œ", "æƒ…æ„Ÿè¡¨è¾¾"],
        index=["ç»¼åˆæ¨è", "å£è¯­äº¤æµ", "å•†åŠ¡ä¹¦é¢", "å­¦æœ¯å†™ä½œ", "æƒ…æ„Ÿè¡¨è¾¾"].index(st.session_state.style_preference)
    )
    
    if style_preference != st.session_state.style_preference:
        st.session_state.style_preference = style_preference
        st.success(f"å·²åˆ‡æ¢åˆ°: {style_preference}é£æ ¼")

# èŠå¤©è¾“å…¥æ¡†
user_input = st.chat_input("è¾“å…¥æ‚¨æƒ³è¡¨è¾¾çš„ä¸­æ–‡å†…å®¹...")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯è‹±æ–‡è¡¨è¾¾å‚è€ƒåŠ©æ‰‹ï¼Œè¯·è¾“å…¥ä¸­æ–‡å†…å®¹ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›å¤šç§æƒ…æ™¯çš„è‹±æ–‡è¡¨è¾¾å‚è€ƒã€‚"}
    ]

# æ˜¾ç¤ºå¯¹è¯å†å²
for message in st.session_state.messages:
    st.chat_message(message["role"]).write(message["content"])

# è·å–æç¤ºè¯æ¨¡æ¿
def get_expression_prompt(style_preference):
    """æ ¹æ®é£æ ¼åå¥½è·å–æç¤ºè¯æ¨¡æ¿"""
    
    style_instructions = {
        "ç»¼åˆæ¨è": "æä¾›3-4ç§ä¸åŒé£æ ¼çš„è‹±æ–‡è¡¨è¾¾ï¼ŒåŒ…æ‹¬å£è¯­ã€ä¹¦é¢å’Œæƒ…æ„Ÿè¡¨è¾¾ç‰ˆæœ¬",
        "å£è¯­äº¤æµ": "é‡ç‚¹æä¾›è‡ªç„¶ã€åœ°é“çš„å£è¯­è¡¨è¾¾ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯ä½¿ç”¨",
        "å•†åŠ¡ä¹¦é¢": "ä¾§é‡æ­£å¼ã€ä¸“ä¸šçš„å•†åŠ¡å’Œä¹¦é¢è¡¨è¾¾ï¼Œæ³¨æ„ç”¨è¯å‡†ç¡®",
        "å­¦æœ¯å†™ä½œ": "æä¾›å­¦æœ¯è®ºæ–‡ã€æ­£å¼æ–‡æ¡£ä¸­ä½¿ç”¨çš„ä¸¥è°¨è¡¨è¾¾",
        "æƒ…æ„Ÿè¡¨è¾¾": "å¼ºè°ƒæƒ…æ„Ÿè‰²å½©å’Œè¯­æ°”ï¼Œæä¾›ä¸åŒæƒ…æ„Ÿå¼ºåº¦çš„è¡¨è¾¾æ–¹å¼"
    }
    
    system_template = """ä½ æ˜¯ä¸“ä¸šçš„è‹±æ–‡è¡¨è¾¾é¡¾é—®ï¼Œä¸“é—¨å¸®åŠ©ä¸­æ–‡ç”¨æˆ·æ‰¾åˆ°æœ€é€‚åˆæƒ…æ™¯çš„è‹±æ–‡è¡¨è¾¾ã€‚

## ä½ çš„ä»»åŠ¡ï¼š
ç”¨æˆ·è¾“å…¥ä¸­æ–‡å¥å­ï¼Œä½ éœ€è¦æä¾›å¤šç§è‹±æ–‡è¡¨è¾¾æ–¹å¼ï¼Œæ¯ç§è¡¨è¾¾éƒ½è¦ï¼š
1. æ ‡æ³¨é€‚ç”¨åœºæ™¯å’Œé£æ ¼ç‰¹ç‚¹
2. æä¾›ä¸­æ–‡å›è¯‘è¯´æ˜ç»†å¾®å·®åˆ«
3. ç»™å‡ºè¯­æ³•è¦ç‚¹å’Œç”¨è¯åˆ†æ
4. æœ€åç»™å‡ºç»¼åˆæ¨è

## è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
â¸»
[ä¸­æ–‡åŸå¥]
è¿™å¥è¯çš„è‹±æ–‡å¯ä»¥è¿™æ ·è¡¨è¾¾ğŸ‘‡

âœ… [é£æ ¼1åç§°]
[è‹±æ–‡è¡¨è¾¾1]
ï¼ˆ[ä¸­æ–‡å›è¯‘è¯´æ˜ç»†å¾®å·®åˆ«]ï¼‰

â¸»

âœ… [é£æ ¼2åç§°] 
[è‹±æ–‡è¡¨è¾¾2]
ï¼ˆ[ä¸­æ–‡å›è¯‘è¯´æ˜ç»†å¾®å·®åˆ«]ï¼‰

â¸»

âœ… [é£æ ¼3åç§°]
[è‹±æ–‡è¡¨è¾¾3]
ï¼ˆ[ä¸­æ–‡å›è¯‘è¯´æ˜ç»†å¾®å·®åˆ«]ï¼‰

â¸»

ğŸ’¡ è¯­æ³•è¦ç‚¹ï¼š
â€¢ [è¦ç‚¹1]
â€¢ [è¦ç‚¹2]

â¸»

ğŸª„ æ€»ç»“æ¨èï¼š
âœ… [æœ€æ¨èçš„è¡¨è¾¾]
[æ¨èç†ç”±]

è¯·æ ¹æ®ç”¨æˆ·åå¥½ä¾§é‡ï¼š{style_instruction}"""

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("human", "{input}"),
    ])
    
    return prompt_template, style_instructions[style_preference]

# ç”Ÿæˆè‹±æ–‡è¡¨è¾¾å‚è€ƒ
def generate_expression_reference(user_input, style_preference):
    """ç”Ÿæˆå¤šç§è‹±æ–‡è¡¨è¾¾å‚è€ƒ"""
    
    # è·å–æç¤ºè¯æ¨¡æ¿å’Œé£æ ¼è¯´æ˜
    prompt_template, style_instruction = get_expression_prompt(style_preference)
    
    # åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯ - ä½¿ç”¨å®‰å…¨çš„api_keyå˜é‡
    client = ChatOpenAI(
        api_key=api_key,  # â† æ”¹ä¸ºä½¿ç”¨ä¸Šé¢å®šä¹‰çš„api_keyå˜é‡
        model="deepseek-chat",
        base_url="https://api.deepseek.com",
        temperature=0.3,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´å¤šåˆ›é€ æ€§è¡¨è¾¾
    )
    
    # åˆ›å»ºå¯¹è¯é“¾
    chain = LLMChain(llm=client, prompt=prompt_template)
    
    # ç”Ÿæˆå›å¤
    response = chain.run(
        input=user_input,
        style_instruction=style_instruction
    )
    
    return response

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input:
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("human").write(user_input)
    st.session_state.messages.append({"role": "human", "content": user_input})
    
    # ç”Ÿæˆè‹±æ–‡è¡¨è¾¾å‚è€ƒ
    with st.spinner("æ­£åœ¨ç”Ÿæˆå¤šç§è‹±æ–‡è¡¨è¾¾å‚è€ƒ..."):
        try:
            response = generate_expression_reference(user_input, st.session_state.style_preference)
            
            # æ˜¾ç¤ºAIå›å¤
            st.chat_message("assistant").write(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
            
            # æ·»åŠ å¤åˆ¶åŠŸèƒ½æç¤º
            st.sidebar.success("ğŸ’¡ æç¤ºï¼šå¯ä»¥å¤åˆ¶æ‚¨å–œæ¬¢çš„è¡¨è¾¾æ–¹å¼")
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆè¡¨è¾¾æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·é‡è¯•: {str(e)}"
            st.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})

# åœ¨ä¾§è¾¹æ æ·»åŠ ä½¿ç”¨æŒ‡å—
with st.sidebar:
    st.divider()
    st.subheader("ğŸ“š ä½¿ç”¨æŒ‡å—")
    st.markdown("""
    **å¦‚ä½•ä½¿ç”¨ï¼š**
    1. åœ¨è¾“å…¥æ¡†è¾“å…¥ä¸­æ–‡å¥å­
    2. é€‰æ‹©åå¥½çš„è¡¨è¾¾é£æ ¼
    3. æŸ¥çœ‹å¤šç§è‹±æ–‡è¡¨è¾¾å‚è€ƒ
    4. é€‰æ‹©æœ€é€‚åˆæ‚¨æƒ…æ™¯çš„è¡¨è¾¾
    
    **é€‚ç”¨åœºæ™¯ï¼š**
    â€¢ æ—¥å¸¸å£è¯­äº¤æµ
    â€¢ å•†åŠ¡é‚®ä»¶å†™ä½œ  
    â€¢ å­¦æœ¯è®ºæ–‡è¡¨è¾¾
    â€¢ æƒ…æ„Ÿè¡¨è¾¾ä¼˜åŒ–
    """)
    
    # æ˜¾ç¤ºç¤ºä¾‹
    st.divider()
    st.subheader("ğŸ¯ ç¤ºä¾‹è¾“å…¥")
    st.code("""
æˆ‘ä»¥ä¸ºä»–ä»¬ä¼šæ„Ÿåˆ°æ²®ä¸§ï¼Œå› ä¸ºä¸‹é›¨ï¼Œä¸èƒ½å¤–å‡ºã€‚
ä»Šå¤©çš„å·¥ä½œè¿›å±•å¾ˆé¡ºåˆ©ã€‚
è¿™ä¸ªæƒ³æ³•å¬èµ·æ¥å¾ˆæœ‰åˆ›æ„ã€‚
    """, language="text")